#! /usr/bin/env python

"""
Extract activation from DNN
"""

import argparse
import numpy as np

from torch.utils.data import DataLoader
from torchvision import transforms
from dnnbrain.dnn.io import NetLoader, ImgDataset, VidDataset, ActWriter
from dnnbrain.utils.io import read_stim_csv
from dnnbrain.dnn.analyzer import dnn_activation


def main():
    parser = argparse.ArgumentParser(description='Extract activation from DNN')
    parser.add_argument('-net',
                        metavar='Net',
                        required=True,
                        type=str,
                        help='a neural network name')
    parser.add_argument('-layer',
                        metavar='Layer',
                        required=True,
                        type=str,
                        nargs='+',
                        help="names of the layers used to specify where activation is extracted from "
                             "For example, 'conv1' represents the first convolution layer, and "
                             "'fc1' represents the first full connection layer. ")
    parser.add_argument('-stim',
                        metavar='Stimulus',
                        required=True,
                        type=str,
                        help='a .stim.csv file which contains stimulus information')
    parser.add_argument('-out',
                        metavar='Output',
                        required=True,
                        type=str,
                        help='an output filename with suffix .act.h5')
    args = parser.parse_args()

    # -load DNN-
    net_loader = NetLoader(args.net)
    transform = transforms.Compose([transforms.Resize(net_loader.img_size), transforms.ToTensor()])

    # -load stimuli-
    stim_dict = read_stim_csv(args.stim)
    if stim_dict['type'] == 'image':
        dataset = ImgDataset(stim_dict['path'], stim_dict['stim']['stimID'],
                             transform=transform)
    elif stim_dict['type'] == 'video':
        dataset = VidDataset(stim_dict['path'], stim_dict['stim']['stimID'],
                             transform=transform)
    else:
        raise TypeError('{} is not a supported stimulus type.'.format(stim_dict['type']))
    data_loader = DataLoader(dataset, batch_size=8, shuffle=False)

    # -extract activation-
    n_stim = len(dataset)
    writer = ActWriter(args.out, args.net + ' act')
    for layer in args.layer:
        dnn_acts = []
        for stims, _ in data_loader:
            dnn_acts.extend(dnn_activation(stims, net_loader.model, net_loader.layer2keys[layer]))
            print('Extracted acts: {0}/{1}'.format(len(dnn_acts), n_stim))
        dnn_acts = np.array(dnn_acts)
        raw_shape = dnn_acts.shape
        dnn_acts = dnn_acts.reshape((raw_shape[0], raw_shape[1], -1))

        # write to file
        writer.set_act(layer, dnn_acts)
        writer.set_attr(layer, 'raw_shape', raw_shape)

    writer.close()


if __name__ == '__main__':
    main()
