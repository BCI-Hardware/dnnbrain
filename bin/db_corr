#! /usr/bin/env python

"""
Correlate DNN activation with brain or behavior response
"""

import os
import time
import argparse
import numpy as np
import pandas as pd

from os.path import join as pjoin
from dnnbrain.dnn.core import Activation
from dnnbrain.brain.core import ROI
from dnnbrain.brain.io import load_brainimg, save_brainimg
from dnnbrain.utils.util import gen_dmask
from sklearn.metrics import pairwise_distances


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-act',
                        metavar='Activation',
                        required=True,
                        type=str,
                        help='DNN activation file')
    parser.add_argument('-layer',
                        metavar='Layer',
                        type=str,
                        nargs='+',
                        help="layer names of interest "
                             "For example, 'conv1' represents the first convolution layer, and "
                             "'fc1' represents the first full connection layer. ")
    parser.add_argument('-chn',
                        metavar='Channel',
                        type=int,
                        nargs='+',
                        help="channel numbers of interest "
                             "Default is using all channels of each layer specified by -layer.")
    parser.add_argument('-dmask',
                        metavar='DnnMask',
                        type=str,
                        help='a .dmask.csv file in which layers of interest are listed '
                             'with their own channels, rows and columns of interest.')
    parser.add_argument('-iteraxis',
                        type=str,
                        metavar='Axis',
                        choices=('channel', 'row_col'),
                        help="Iterate along the specified axis."
                             "channel: Summarize the maximal R square for each channel. "
                             "row_col: Summarize the maximal R square for each position (row_idx, col_idx). "
                             "default: Summarize the maximal R square for the whole layer.")
    parser.add_argument('-resp',
                        metavar='Response',
                        required=True,
                        type=str,
                        help='a .roi.h5/.nii file '
                             'If it is .nii file, -roi will be ignored. '
                             "All voxels' activation will be a correlate.")
    parser.add_argument('-bmask',
                        metavar='BrainMask',
                        type=str,
                        help='Brain mask is used to extract activation locally. '
                             'Only used when the response file is .nii file.')
    parser.add_argument('-roi',
                        metavar='RoiName',
                        type=str,
                        nargs='+',
                        help='Specify ROI names as the correlates. '
                             'Default is using all ROIs in .roi.h5 file.')
    parser.add_argument('-out',
                        metavar='Output',
                        required=True,
                        type=str,
                        help='R square and position in an output directory')
    args = parser.parse_args()

    # -Load response start-
    if args.resp.endswith('.roi.h5'):
        roi = ROI(args.resp, args.roi)
        Y = roi.data

    elif args.resp.endswith('.nii') or args.resp.endswith('.nii.gz'):
        Y, header = load_brainimg(args.resp)
        bshape = Y.shape[1:]

        # Get resp data within brain mask
        if args.bmask is None:
            bmask = np.any(Y, 0)
        else:
            bmask, _ = load_brainimg(args.bmask, ismask=True)
            assert bshape == bmask.shape, 'brain mask and brain response mismatched in space'
            bmask = bmask.astype(np.bool)
        Y = Y[:, bmask]

    else:
        raise IOError('Only .roi.h5 and nifti/cifti are supported')
    n_samp, n_meas = Y.shape  # n_sample x n_measures
    print('Finish loading response: ', args.resp)
    # -Load response end-

    # -load activation start-
    # initialize DNN mask
    if args.layer is None and args.dmask is None:
        dmask = None
    else:
        dmask = gen_dmask(args.layer, args.chn, args.dmask)
    activation = Activation(args.act, dmask)
    print('Finish loading activation: ', args.act)
    # -load activation end-

    # -correlation start-
    for layer in activation.layers:
        time1 = time.time()
        # get DNN activation and reshape it to 3D
        dnn_acts = activation.get(layer)
        n_stim, n_chn, n_row, n_col = dnn_acts.shape
        assert n_stim == n_samp, 'n_stim != n_samp'
        n_row_col = n_row * n_col
        dnn_acts = dnn_acts.reshape((n_stim, n_chn, n_row_col))

        # transpose axis to make dnn_acts's shape as (n_stimulus, n_iterator, n_element)
        if args.iteraxis is None:
            dnn_acts = dnn_acts.reshape((n_stim, 1, -1))
        elif args.iteraxis == 'row_col':
            dnn_acts = dnn_acts.transpose((0, 2, 1))
        elif args.iteraxis == 'channel':
            pass
        else:
            raise ValueError("Unspported iteraxis:", args.iteraxis)
        n_stim, n_iter, n_elem = dnn_acts.shape

        # prepare container
        score_arr = np.zeros((n_iter, n_meas), dtype=np.float)
        channel_arr = np.zeros_like(score_arr, dtype=np.int)
        row_arr = np.zeros_like(score_arr, dtype=np.int)
        column_arr = np.zeros_like(score_arr, dtype=np.int)

        # start iteration
        for meas_idx in range(n_meas):
            for iter_idx in range(n_iter):
                # calculate correlation
                X = dnn_acts[:, iter_idx, :].T
                y = Y[:, meas_idx].reshape(1, -1)
                score_tmp = pairwise_distances(X, y, 'correlation')
                score_tmp = (1 - score_tmp.ravel()) ** 2

                # find max score
                max_elem_idx = np.argmax(score_tmp)
                max_score = score_tmp[max_elem_idx]
                score_arr[iter_idx, meas_idx] = max_score

                # find position for the max score
                if args.iteraxis is None:
                    chn_idx = max_elem_idx // n_row_col
                    row_idx = max_elem_idx % n_row_col // n_col
                    col_idx = max_elem_idx % n_row_col % n_col
                elif args.iteraxis == 'channel':
                    chn_idx = iter_idx
                    row_idx = max_elem_idx // n_col
                    col_idx = max_elem_idx % n_col
                else:
                    chn_idx = max_elem_idx
                    row_idx = iter_idx // n_col
                    col_idx = iter_idx % n_col

                channel_arr[iter_idx, meas_idx] = chn_idx + 1
                row_arr[iter_idx, meas_idx] = row_idx + 1
                column_arr[iter_idx, meas_idx] = col_idx + 1
                print(f'Layer: {layer} Meas: {meas_idx+1}/{n_meas}; iter: {iter_idx+1}/{n_iter}')
        print(f'Finish correlation for {layer}, cost {time.time()-time1} seconds.')

        # --save out start--
        # prepare directory
        trg_dir = pjoin(args.out, layer)
        if not os.path.isdir(trg_dir):
            os.makedirs(trg_dir)
        if args.iteraxis is not None:
            trg_dir = pjoin(trg_dir, args.iteraxis)
            if not os.path.isdir(trg_dir):
                os.makedirs(trg_dir)

        # save files
        if args.resp.endswith('.roi.h5'):
            # save score
            score_df = pd.DataFrame(score_arr, columns=roi.rois)
            score_df.to_csv(pjoin(trg_dir, 'score_corr.csv'), index=False)
            del score_arr

            # save position
            chn_pos_df = pd.DataFrame(channel_arr, columns=roi.rois)
            chn_pos_df.to_csv(pjoin(trg_dir, 'chn_position.csv'), index=False)
            del channel_arr
            row_pos_df = pd.DataFrame(row_arr, columns=roi.rois)
            row_pos_df.to_csv(pjoin(trg_dir, 'row_position.csv'), index=False)
            del row_arr
            col_pos_df = pd.DataFrame(column_arr, columns=roi.rois)
            col_pos_df.to_csv(pjoin(trg_dir, 'col_position.csv'), index=False)
            del column_arr

        else:
            resp_suffix = '.'.join(args.resp.split('.')[1:])

            # save score
            score_img = np.zeros((n_iter, *bshape))
            score_img[:, bmask] = score_arr
            save_brainimg(pjoin(trg_dir, 'score_corr.' + resp_suffix), score_img, header)
            del score_arr

            # save position
            chn_pos_img = np.zeros_like(score_img, dtype=np.int)
            chn_pos_img[:, bmask] = channel_arr
            save_brainimg(pjoin(trg_dir, 'chn_position.' + resp_suffix), chn_pos_img, header)
            del channel_arr
            row_pos_img = np.zeros_like(score_img, dtype=np.int)
            row_pos_img[:, bmask] = row_arr
            save_brainimg(pjoin(trg_dir, 'row_position.' + resp_suffix), row_pos_img, header)
            del row_arr
            col_pos_img = np.zeros_like(score_img, dtype=np.int)
            col_pos_img[:, bmask] = column_arr
            save_brainimg(pjoin(trg_dir, 'col_position.' + resp_suffix), col_pos_img, header)
            del column_arr
        print(f'Finish saving for {layer}')
        # --save out end--


if __name__ == '__main__':
    main()
