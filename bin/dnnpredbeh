#! /usr/bin/env python

"""
Use CNN activation to predict behavior measurement

Author: Taicheng Huang @ BNU
Email: taicheng_huang@mail.bnu.edu.cn
Reviewer:
"""

import os
import argparse
import subprocess
import numpy as np
from torchvision import transforms
from torch.utils.data import DataLoader
import pandas as pd
from scipy import stats
from dnnbrain.core import model_operation
from dnnbrain.utils import iofiles

try:
    from sklearn import linear_model, model_selection, decomposition
except ModuleNotFoundError:
    raise Exception('Please install sklearn in your workstation')

def main():
    parser = argparse.ArgumentParser(description='Use CNN activation to predict behavior measurement')
    parser.add_argument('-net',
                        type=str,
                        required=True,
                        metavar='NetName',
                        help='convolutional network name')
    parser.add_argument('-layer',
                        type=str,
                        required=True,
                        metavar='LayerName',
                        help='activation for specific layers, please input conv1 or fc1 for activation')
    parser.add_argument('-channel',
                        type=int,
                        required=False,
                        nargs='*',
                        metavar='Channel',
                        help='activation for specific channels')
    parser.add_argument('-stim',
                        type=str,
                        required=True,
                        dest='csv'
                        metavar='StimuliInfoFile',
                        help='table contains picture names, conditions and picture onset time.\
                              This csv_file helps us connect cnn activation to brain images.\
                              Please organize your information as:\
                              [PicPath]\
                              stimID     condition   onset(optional) measurement(optional)\
                              face1.png  face        1.1             3\
                              face2.png  face        3.1             5\
                              scene1.png scene       5.1             4'
                        )
    parser.add_argument('-behavior',
                        type=str,
                        required=True,
                        metavar='BehaviorMeasurement',
                        help='behavior measurement extracted from csv. This code will extracte\
                              behavior measurement with key from the csv_file (see above \
                              parameter -csv).')
    parser.add_argument('-model',
                        type=str,
                        required=False,
                        metavar='BrainModel',
                        choices=['multivariate', 'univariate'],
                        default='multivariate',
                        help='model to predict brain activation by CNN activation, by default is multivariate.\
                              multivariate analysis calls lasso regression with default alpha = 1, and we will \
                              first decompose activation data of DNN into 200 dimension and then calculate \
                              explained variance by using cross validation. \
                              univariate analysis, we will do linear cross validation in each brain image voxel \
                              with each units and return the maximum explained variance as the explained variance \
                              of brain activation.')
    parser.add_argument('-cvfold',
                        type=int,
                        required=False,
                        default=2,
                        metavar='FoldNumber',
                        help='cross validation fold numbers')
    parser.add_argument('-out',
                        type=str,
                        required=True,
                        dest='OutputDir',
                        metavar='Output Directory',
                        help='output directory, output is text file with each value\
                              is explained_variance by multivariate or univariate analysis \
                              in each layer.')
    args = parser.parse_args()

	# DNN activation extraction 
    netloader = iofiles.NetLoader(args.net)
    imgcropsize = netloader.img_size
     
    transform = transforms.Compose([transforms.Resize(imgcropsize),
                                    transforms.ToTensor()])                            
    picdataset = iofiles.PicDataset(args.csv, transform=transform)
    picdataloader = DataLoader(picdataset, batch_size=8, shuffle=False)
    dnn_act = model_operation.dnn_activation(picdataloader, args.net, args.layer, args.channel)
    if dnn_act.ndim == 3:
        dnn_act = dnn_act[:,None,...]
    
    # Reshape dnn_act and flatten its unit
    channel_num = dnn_act.shape[1]
    dnn_act = dnn_act.reshape((dnn_act.shape[0], channel_num*dnn_act.shape[2]*dnn_act.shape[3]))
    
    # Get behavior measurement
    csv_table = pd.read_csv(args.csv, skiprows=1)
    beh_measure = np.array(csv_table[args.behavior])[:,None]
	
    # Initialize machine learning models
    if args.model == 'multivariate':
        model = linear_model.LinearRegression()
        
    scores = []
    # Multivariate regression analysis
    if args.model == 'multivariate':
        if dnn_act.shape[0] < 10:
            comp_num = dnn_act.shape[0]
        else:
            comp_num = 10
        pca = decomposition.PCA(n_components=comp_num)
        # nsamples(pics)*nfeatures(units)
        # Decrease dimension using PCA
        dnn_act_pca = pca.fit_transform(dnn_act)
        # Cross validation
        scores_tmp = model_selection.cross_val_score(model, dnn_act_pca, beh_measure, scoring='explained_variance', cv=args.cvfold)
        scores.append(np.mean(scores_tmp))
    # Univariate regression analysis
        # get the maximum value of explained_variance across all DNN units in a channel
    elif args.model == 'univariate':
        # nsamples(pics)*nfeatures(units) in one layer
        # Iterate across units
        scores_tmp = []
        for j in range(dnn_act.shape[1]): 
            dnnactlist_tmp = dnn_act[:,j][:,None]
            r, _ = stats.pearsonr(beh_measure, dnnactlist_tmp)
            scores_tmp.append(r)
        scores.append(np.max(scores_tmp))
    else:
        raise Exception('Not supported yet, please contact the author for implementation.')
    scores = np.array(scores)
    
    # Save behavior measurement into hardware
    np.savetxt(args.outdir, scores, delimiter=',')

if __name__ == '__main__':
    main()
