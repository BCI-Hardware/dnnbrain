#! /usr/bin/env python

"""
Use CNN activation to predict brain activation by training a new FC layer

Author: Xiayu Chen @ BNU
Email: sunshine_drizzle@foxmail.com
"""

import torch
import numpy as np

from torch import nn
from torch.utils.data import DataLoader, TensorDataset
from torchvision import transforms
from scipy.stats import pearsonr
from os.path import join as pjoin
from sklearn.model_selection import KFold
from dnnbrain.dnn.models import DNN2BrainNet
from dnnbrain.dnn.analyzer import truncate_net
from dnnbrain.utils.iofiles import NetLoader, PicDataset, load_brainimg, save_brainimg


def main():
    import argparse

    parser = argparse.ArgumentParser(description="DNN connect brain")
    parser.add_argument('-net',
                        metavar='NetName',
                        required=True,
                        type=str,
                        dest='net_name',
                        help="a pretrained neural network's name such as 'alexnet' and 'vgg11'")
    parser.add_argument('-layer',
                        metavar='LayerName',
                        required=True,
                        type=str,
                        help="The name of the layer which is connected to predict brain activity."
                             "For example, 'conv1' represents the first convolution layer, and"
                             "'fc1' represents the first full connection layer."
                             "(Notice: there is a BUG when trying extract 'fc' layer!)")
    parser.add_argument('-channel',
                        metavar='ChannelNumber',
                        type=int,
                        nargs='*',
                        help="The sequence numbers of out channels of the selected layer"
                             "If not specified, use all out channels.")
    parser.add_argument('-stim',
                        metavar='StimuliInfoFile',
                        required=True,
                        type=str,
                        help="map stimulus with brain activation")
    parser.add_argument('-brainact',
                        metavar='BrainActFile',
                        required=True,
                        type=str,
                        help="brain activation data file")
    parser.add_argument('-mask',
                        metavar='MaskFile',
                        type=str,
                        help="brain mask used to extract activation locally")
    parser.add_argument('-roi',
                        action='store_true',
                        help="Do ROI-level analysis when the argument is used.")
    parser.add_argument('-cvfold',
                        metavar='FoldNumber',
                        type=int,
                        help="cross validation fold number")
    parser.add_argument('-out',
                        metavar='OutputDir',
                        required=True,
                        type=str,
                        help="output directory")
    args = parser.parse_args()

    # ---prepare net---
    net_loader = NetLoader(args.net_name)
    # truncate the pretrained neural network
    truncated_net = truncate_net(net_loader.model, net_loader.layer2indices[args.layer])
    for param in truncated_net.parameters():
        # fix the pretrained parameters
        param.requires_grad = False

    # ---prepare data---
    # prepare pictures
    pic_dataset = PicDataset(args.stim, transforms.Compose([transforms.Resize(net_loader.img_size),
                                                            transforms.ToTensor()]))
    pic_dataloader = DataLoader(pic_dataloader, batch_size=1, shuffle=False)
    pics = torch.tensor([pic.numpy() for _, pic, _ in pic_dataloader])
    pics.squeeze_(1)
    truncated_output = truncated_net(pics[0].unsqueeze(0))
    channel_unit_num = truncated_output.shape[2:].numel()

    # load brain activation data
    acts_src, header = load_brainimg(args.brainact)

    # prepare mask
    if args.mask:
        mask, header = load_brainimg(args.mask, ismask=True)
    else:
        mask = np.sum(acts_src, 0) != 0

    # extract signals in mask
    acts = []
    if args.roi and args.mask:
        labels = np.delete(np.unique(mask), 0).astype(int)
        for act in acts_src:
            acts_sub = []
            for label in labels:
                acts_sub.append(np.mean(act[mask == label]))
            acts.append(acts_sub)
    else:
        for act in acts_src:
            acts.append(act[mask != 0])
    acts = torch.tensor(acts)

    if args.cvfold:
        # split data to args.cvfold folds
        # Each fold is then used once as a validation while the args.cvfold - 1 remaining folds form the training set.
        scores_list = []
        kf = KFold(args.cvfold)
        for train_indices, test_indices in kf.split(pics):
            # train a new model
            train_pics = pics[train_indices]
            train_acts = acts[train_indices]
            net = training(train_pics, train_acts, truncated_net, channel_unit_num, args.channel)

            # test the trained model
            test_pics = pics[test_indices]
            test_acts = acts[test_indices]
            net.train(False)
            with torch.no_grad():
                predicted_acts = net(test_pics)

            # calculate prediction score
            scores = []
            for x, y in zip(test_acts.numpy().T, predicted_acts.numpy().T):
                r = pearsonr(x, y)[0]
                if np.isnan(r):
                    r = 0
                scores.append(np.power(r, 2))
            scores_list.append(scores)
        scores_avg = np.nanmean(scores_list, 0)

        # save
        if args.roi:
            save_roi_score(args.out, scores_avg, labels)
        else:
            save_voxel_score(args.out, scores_avg, mask, header)
    else:
        # use all data to train a model
        net = training(pics, acts, truncated_net, channel_unit_num, args.channel)
        net.train(False)
        with torch.no_grad():
            predicted_acts = net(pics)

        # calculate prediction score
        scores = []
        for x, y in zip(acts.numpy().T, predicted_acts.numpy().T):
            r = pearsonr(x, y)[0]
            if np.isnan(r):
                r = 0
            scores.append(np.power(r, 2))

        if args.roi:
            save_roi_score(args.out, scores, labels)
        else:
            save_voxel_score(args.out, scores, mask, header)

        net_file = pjoin(args.out, 'dnn2brain_net.pkl')
        torch.save(net, net_file)


def training(pics, acts, truncated_net, channel_unit_num, channel):
    """

    Parameters:
    -----------
    pics[torch.Tensor]: a 4D tensor with the shape (#pictures, #channels, picture_size1, picture_size2)
    acts[torch.Tensor]: a 2D tensor with the shape (#pictures, #voxels) or (#pictures, #ROIs)
    truncated_net[torch.nn.Module]: a truncated neural network
    channel_unit_num[int]: the number of units of each channel of the last layer in the truncated network
    channel[iterator]: The sequence numbers of out channels of the selected layer.

    Returns:
    --------
    net[torch.nn.Module]: a trained model
    """
    # ---create Dataset and DataLoader---
    # dataset = TensorDataset(pics, acts)
    # train_loader = DataLoader(dataset=dataset, batch_size=2, shuffle=True, num_workers=1)

    # ---create new network---
    net = DNN2BrainNet(
        truncated_net=truncated_net,
        channel_unit_num=channel_unit_num,
        fc_out_num=acts.shape[1],
        channel=channel
    )

    # ---training---
    net.train(True)
    optimizer = torch.optim.Adam(net.fc.parameters(), lr=0.01)
    loss_func = nn.MSELoss()
    pics.requires_grad_(True)
    for epoch in range(100):
        output = net(pics)
        loss = loss_func(output, acts)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # output information
        print('Epoch:', epoch+1, '\t| Loss:', loss.item())

    return net


def save_roi_score(out_dir, scores, labels):
    """
    save roi prediction score in csv file

    Parameters:
    -----------
    out_dir[str]: output directory
    scores[iterator]: roi prediction scores
    labels[iterator]: roi labels
    """
    contents = [','.join(pair) for pair in zip(map(str, labels), map(str, scores))]
    contents.insert(0, 'ROI,score')
    contents = '\n'.join(contents)
    score_file = pjoin(out_dir, 'roi_score.csv')
    open(score_file, 'w+').writelines(contents)


def save_voxel_score(out_dir, scores, mask, header=None):
    """
    save voxel prediction score in brain file

    out_dir[str]: output directory
    scores[iterator]: voxel prediction scores
    mask[np.ndarray]: brain mask used to extract activation locally
    """
    brainimg = np.zeros_like(mask, dtype=np.float)
    brainimg[mask != 0] = scores
    brainimg = np.expand_dims(brainimg, 0)
    score_file = pjoin(out_dir, 'voxel_score.nii.gz')
    save_brainimg(score_file, brainimg, header)


if __name__ == '__main__':
    main()
