#! /usr/bin/env python

"""
Probe the ability of DNN activation to predict behavior.
"""

import os
import time
import argparse
import numpy as np
import pandas as pd

from os.path import join as pjoin
from dnnbrain.dnn.core import Stimulus, Activation, DnnProbe
from dnnbrain.utils.util import gen_dmask


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-anal',
                        metavar='Analysis',
                        required=True,
                        type=str,
                        choices=('uv', 'mv'),
                        help="uva: Do univariate analysis. "
                             "mva: Do multivariate analysis.")
    parser.add_argument('-act',
                        metavar='Activation',
                        required=True,
                        type=str,
                        help='DNN activation file')
    parser.add_argument('-layer',
                        metavar='Layer',
                        type=str,
                        nargs='+',
                        help="layer names of interest "
                             "For example, 'conv1' represents the first convolution layer, and "
                             "'fc1' represents the first full connection layer. ")
    parser.add_argument('-chn',
                        metavar='Channel',
                        type=int,
                        nargs='+',
                        help="channel numbers of interest "
                             "Default is using all channels of each layer specified by -layer.")
    parser.add_argument('-dmask',
                        metavar='DnnMask',
                        type=str,
                        help='a .dmask.csv file in which layers of interest are listed '
                             'with their own channels, rows and columns of interest.')
    parser.add_argument('-iteraxis',
                        type=str,
                        metavar='Axis',
                        choices=('channel', 'row_col'),
                        help="Iterate along the specified axis."
                             "If -anal is uva:"
                             "channel: Summarize the maximal prediction score for each channel. "
                             "row_col: Summarize the maximal prediction score for each location (row_idx, col_idx). "
                             "default: Summarize the maximal prediction score for the whole layer."
                             "If -anal is mva:"
                             "channel: Do mva using all units in each channel. "
                             "row_col: Do mva using all units in each location (row_idx, col_idx). "
                             "default: Do mva using all units in the whole layer.")
    parser.add_argument('-stim',
                        metavar='Stimulus',
                        required=True,
                        type=str,
                        help='a .stim.csv file which contains behavior data')
    parser.add_argument('-beh',
                        metavar='Behavior',
                        required=True,
                        type=str,
                        nargs='+',
                        help='Specify behaviors as the ground truth. ')
    parser.add_argument('-model',
                        metavar='Model',
                        required=True,
                        type=str,
                        choices=('glm', 'lasso', 'svc', 'lrc', 'corr'),
                        help='Select a model to do prediction. '
                             'Use glm (general linear model) for regression. '
                             'Use lasso (lasso regression) for regression. '
                             'Use svc (support vector machine) for classification. '
                             'Use lrc (logistic regression) for classification.'
                             'Use corr (pearson correlation) for correlation analysis.')
    parser.add_argument('-cv',
                        metavar='FoldNumber',
                        type=int,
                        default=3,
                        help='cross validation fold number')
    parser.add_argument('-out',
                        metavar='Output',
                        required=True,
                        type=str,
                        help='an output directory')
    args = parser.parse_args()

    # -load behavior data-
    stimuli = Stimulus()
    stimuli.load(args.stim)
    beh_data = []
    for beh in args.beh:
        beh_data.append(stimuli.get(beh))
    beh_data = np.asarray(beh_data).T
    print('Finish loading behavior: ', args.beh)
    # -load behavior end-

    # -load DNN activation start-
    # initialize DNN mask
    if args.layer is None and args.dmask is None:
        dmask = None
    else:
        channels = 'all' if args.chn is None else args.chn
        dmask = gen_dmask(args.layer, channels, args.dmask)
    activation = Activation()
    activation.load(args.act, dmask)
    print('Finish loading DNN activation: ', args.act)
    # -load DNN activation end-

    # -probe start-
    time1 = time.time()
    probe = DnnProbe(activation, args.anal, args.model, args.cv)
    probe_dict = probe.probe(beh_data, args.iteraxis)
    print('Finish probe: cost {} seconds.'.format(time.time()-time1))
    # -probe end-

    # -save out start-
    for layer, data in probe_dict.items():
        # prepare directory
        trg_dir = pjoin(args.out, layer)
        if not os.path.isdir(trg_dir):
            os.makedirs(trg_dir)
        if args.iteraxis is not None:
            trg_dir = pjoin(trg_dir, args.iteraxis)
            if not os.path.isdir(trg_dir):
                os.makedirs(trg_dir)

        for k, v in data.items():
            if k == 'max_score':
                df = pd.DataFrame(v, columns=args.beh)
                df.to_csv(pjoin(trg_dir, '{}.csv'.format(k)), index=False)
            else:
                np.save(pjoin(trg_dir, k), v)

        print('Finish save {}.'.format(layer))
    # -save out end-


if __name__ == '__main__':
    main()
