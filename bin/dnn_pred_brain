#! /usr/bin/env python

"""
Use CNN activation to predict brain activation

Author: Taicheng Huang, Xiayu Chen @ BNU
Email: taicheng_huang@mail.bnu.edu.cn
Reviewer:
"""

import argparse
import numpy as np
import pandas as pd
import torch
from torch import nn
from torch.utils.data import DataLoader, TensorDataset
from torchvision import transforms
from os.path import join as pjoin
from scipy.stats import pearsonr
from dnnbrain.dnn import analyzer
from dnnbrain.dnn import io as dnn_io
from dnnbrain.brain import io as brain_io
from dnnbrain.dnn.models import dnn_truncate, DNN2BrainNet, dnn_train_model


try:
    from sklearn import linear_model, model_selection, decomposition
except ModuleNotFoundError:
    raise Exception('Please install sklearn in your workstation')
    

def main():
    parser = argparse.ArgumentParser(description='Use CNN activation to predict brain activation')
    parser.add_argument('-net',
                        type=str,
                        required=True,
                        metavar='NetName',
                        help='convolutional network name')
    parser.add_argument('-layer',
                        type=str,
                        required=True,
                        metavar='LayerName',
                        help="The name of the layer whose activation is used to predict brain activity. "
                             "For example, 'conv1' represents the first convolution layer, and "
                             "'fc1' represents the first full connection layer.")
    parser.add_argument('-channel',
                        type=int,
                        required=False,
                        nargs='*',
                        metavar='Channel',
                        help="The sequence numbers of out_channels of the selected layer. "
                             "If not specified, use all out_channels' activation to predict brain activity.")
    parser.add_argument('-stim',
                        type=str,
                        required=True,
                        dest='csv',
                        metavar='StimuliInfoFile',
                        help='table contains picture names, conditions and picture onset time.\
                                This csv_file helps us connect cnn activation to brain images.\
                                Please organize your information as:\
                                [PicPath]\
                                stimID     condition   onset(optional) measurement(optional)\
                                face1.png  face        1.1             3\
                                face2.png  face        3.1             5\
                                scene1.png scene       5.1             4'
                        )
    parser.add_argument('-brainact',
                        type=str,
                        required=True,
                        metavar='BrainActFile',
                        help='brain activation nifti/surface file,\
                                user should correspond brain image \
                                to picture stimuli before calling this\
                                script.')
    parser.add_argument('-mask',
                        type=str,
                        required=False,
                        metavar='MaskFile',
                        help='brain mask used to extract activation locally')
    parser.add_argument('-roi',
                        action='store_true',
                        help='Do ROI analysis or not.')
    parser.add_argument('-model',
                        type=str,
                        required=False,
                        metavar='BrainModel',
                        choices=['glm', 'lasso', 'nn'],
                        help='model to predict brain activation by CNN activation. multivariate analysis \
                              calls linear regression or lasso regression with default alpha = 1, and we will \
                              first decompose activation data of DNN into 200 dimension and then calculate \
                              explained variance by using cross validation.')
    parser.add_argument('-cvfold',
                        type=int,
                        required=False,
                        metavar='FoldNumber',
                        help='cross validation fold number')
    parser.add_argument('-out',
                        type=str,
                        required=True,
                        dest='outdir',
                        metavar='OutputDir',
                        help='output directory, output is a 4D brain image data with value in each voxel \
                              is explained_variance by linear_model, each volume is the prediction explained \
                              variance in each layer.')
    args = parser.parse_args()

    # ---prepare data---
    # prepare pictures
    netloader = dnn_io.NetLoader(args.net)
    imgcropsize = netloader.img_size
    transform = transforms.Compose([transforms.Resize(imgcropsize),
                                    transforms.ToTensor()])                            
    picdataset = dnn_io.PicDataset(args.csv, transform=transform)
    
    # prepare brain images
    brainimg_data_raw, header = brain_io.load_brainimg(args.brainact)
    if args.mask:
        brainmask_data_raw, header = brain_io.load_brainimg(args.mask, ismask=True)
    else:
        brainmask_data_raw = np.sum(brainimg_data_raw, 0) != 0
    assert brainimg_data_raw.shape[1:] == brainmask_data_raw.shape, "Shape of brainact and mask need to be same."
    
    if args.roi and args.mask:
        roilabel = np.delete(np.unique(brainmask_data_raw), 0).astype(int)
        brainact_list = brain_io.extract_brain_activation(brainimg_data_raw, brainmask_data_raw, roilabel).T
        actnode_num = len(roilabel)
    else:
        brainimg_data = brainimg_data_raw*brainmask_data_raw
        brainact_idx = np.transpose(np.where(brainmask_data_raw != 0))
        # Flatten brainimage as (npic * nvoxel) array
        brainact_list = np.zeros((brainimg_data_raw.shape[0], brainact_idx.shape[0]))
        for i, b_idx in enumerate(brainact_idx):
            brainact_list[:, i] = brainimg_data_raw[:, b_idx[0], b_idx[1], b_idx[2]]
        actnode_num = brainact_idx.shape[0]

    # ---Multivariate regression analysis---
    scores = []
    if args.model in ['glm', 'lasso']:
        # Extract brain activation
        picdataloader = DataLoader(picdataset, batch_size=8, shuffle=False)
        dnn_act = analyzer.dnn_activation(picdataloader, args.net, args.layer, args.channel)
        if dnn_act.ndim == 3:
            dnn_act = dnn_act[:, None, ...]
        # Reshape dnn_act and flatten its unit
        dnn_act = dnn_act.reshape((dnn_act.shape[0], dnn_act.shape[1]*dnn_act.shape[2]*dnn_act.shape[3]))

        if args.model == 'glm':
            model = linear_model.LinearRegression()
        elif args.model == 'lasso':
            model = linear_model.Lasso()
        else:
            raise Exception('Not support yet, please contact author for implementation.')
            
        if dnn_act.shape[0] < 10:
            comp_num = dnn_act.shape[0]
        else:
            comp_num = 10
        pca = decomposition.PCA(n_components=comp_num)
        # nsamples(pics)*nfeatures(units)
        for j in range(actnode_num):
            if (j%100 == 0) & (not args.roi):
                print('  Finish calculation on {} voxels'.format(j))
            # nsamples(pics)*nfeatures(voxels)
            # Decrease dimension using PCA
            dnn_act_pca = pca.fit_transform(dnn_act)
            # Cross validation
            cv = 2 if args.cvfold is None else args.cvfold
            scores_tmp = model_selection.cross_val_score(model, dnn_act_pca, brainact_list[:, j][:, None],
                                                         scoring='explained_variance', cv=cv)
            scores.append(np.mean(scores_tmp))

    elif args.model == 'nn':
        # truncate the pretrained neural network
        truncated_net = dnn_truncate(netloader.model, netloader.layer2indices[args.layer], args.layer)
        for param in truncated_net.parameters():
            # fix the pretrained parameters
            param.requires_grad = False

        # process data
        pics = torch.tensor([pic.numpy() for pic, _ in picdataset])
        pics = pics.type(torch.float32)
        truncated_output = truncated_net(pics[0].unsqueeze(0))
        if 'fc' in args.layer:
            channel_unit_num = truncated_output.shape[1]
        elif 'conv' in args.layer:
            channel_unit_num = truncated_output.shape[2:].numel()
        else:
            raise ValueError("Wrong layer name!")
        acts = torch.tensor(brainact_list, dtype=torch.float32)

        if args.cvfold:
            # split data to args.cvfold folds
            # Each fold is then used once as a validation while the remaining folds form the training set.
            scores_list = []
            kf = model_selection.KFold(args.cvfold)
            for train_indices, test_indices in kf.split(pics):
                # train a new model
                train_pics = pics[train_indices]
                train_acts = acts[train_indices]
                dataset = TensorDataset(train_pics, train_acts)
                dataloader = DataLoader(dataset=dataset, batch_size=train_pics.shape[0], num_workers=1)
                net = DNN2BrainNet(
                    truncated_net=truncated_net,
                    channel_unit_num=channel_unit_num,
                    fc_out_num=train_acts.shape[1],
                    channel=args.channel
                )
                optimizer = torch.optim.Adam(net.fc.parameters(), lr=0.01)
                loss_func = nn.MSELoss()
                net = dnn_train_model(dataloader, net, loss_func, optimizer, 100)

                # test the trained model
                test_pics = pics[test_indices]
                test_acts = acts[test_indices]
                net.train(False)
                with torch.no_grad():
                    predicted_acts = net(test_pics)

                # calculate prediction score
                scores = []
                for x, y in zip(test_acts.numpy().T, predicted_acts.numpy().T):
                    r = pearsonr(x, y)[0]
                    if np.isnan(r):
                        r = 0
                    scores.append(np.power(r, 2))
                scores_list.append(scores)
            scores = np.nanmean(scores_list, 0)

        else:
            # use all data to train a model
            dataset = TensorDataset(pics, acts)
            dataloader = DataLoader(dataset=dataset, batch_size=pics.shape[0], num_workers=1)
            net = DNN2BrainNet(
                truncated_net=truncated_net,
                channel_unit_num=channel_unit_num,
                fc_out_num=acts.shape[1],
                channel=args.channel
            )
            optimizer = torch.optim.Adam(net.fc.parameters(), lr=0.01)
            loss_func = nn.MSELoss()
            net = dnn_train_model(dataloader, net, loss_func, optimizer, 100)

            # calculate prediction score
            net.train(False)
            with torch.no_grad():
                predicted_acts = net(pics)
            for x, y in zip(acts.numpy().T, predicted_acts.numpy().T):
                r = pearsonr(x, y)[0]
                if np.isnan(r):
                    r = 0
                scores.append(np.power(r, 2))

            # save net
            net_file = pjoin(args.outdir, 'dnn2brain_net.pkl')
            torch.save(net, net_file)

    else:
        raise Exception('Not support yet, please contact author for implementation.')
    
    # ---save prediction scores---
    if args.roi and args.mask:
        score_df = pd.DataFrame({'ROI': roilabel, 'scores': scores})
        # Save behavior measurement into hardware
        score_df.to_csv(pjoin(args.outdir, 'roi_score.csv'), index=False)
    else:
        # output image: channel*voxels
        out_brainimg = np.zeros((1, *brainimg_data.shape[1:]))
        for i, b_idx in enumerate(brainact_idx):
            out_brainimg[0, b_idx[0], b_idx[1], b_idx[2]] = scores[i]
        # Save image into hardware
        brain_io.save_brainimg(pjoin(args.outdir, 'voxel_score.nii.gz'), out_brainimg, header)


if __name__ == '__main__':
    main()
